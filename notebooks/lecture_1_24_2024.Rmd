---
title: "1/24/2024 Lecture"
output: html_notebook
---

```{r}
library(ISLR2)
library(tidyverse)
```

# Boxplot Annotations (Continued)

```{r}
Auto$cylinders = as_factor(Auto$cylinders)
Auto$origin = as_factor(Auto$origin)
Auto$year = as_factor(Auto$year)
```

Create a dataframe counting the number of samples by region of origin

```{r}
summary.df= tally(group_by(Auto, origin))
summary.df
```

Add additional annotations to the box plot

```{r}
auto.plt = ggplot(Auto)
auto.plt = auto.plt+geom_boxplot(aes(x=origin, y = mpg))
auto.plt = auto.plt+geom_label(data=summary.df, aes(x=origin, label=sprintf("n = %d",n)), 
                       y =max(Auto$mpg), color="red")

print(auto.plt)
```

# Correlations

## Model Problem

Create data

$$
y_i = x_i^3 + \epsilon_i
$$

Think of $\epsilon$ as "noise" in the measurements, and for simplicity, assume $\epsilon_i \sim N(0, \sigma^2)$ for some particular variance, $\sigma$ .

```{r}
set.seed(100) # set a seed for reproducibility
x <- seq(-5, 5, length=101) # 101 uniformly spaced points between -5 and 5
xi <-  rnorm(length(x)) # create a vector of Gaussians with same size as x, N(0,1)
# look at different magnitude noises
sigma2_vals = c(0, 10, 50,100, 500) 

# store in a data structure, data frame, with the columns we want
df <- tibble(x = numeric(), y=numeric(), noise=factor())
df
```

```{r}
#populate the data frame
for(j in 1:length(sigma2_vals)){
  sigma2 = sigma2_vals[j] # get the jth coordinate
  y = x^3 + (sigma2) * xi # add noise with variance sigma2 to x^3, each y is also of same size as x
  df =add_row(df, x = x, y = y, noise = as.factor(sigma2))
}
df
```

```{r}
summary(df)
```

Example of the `filter` command:

This extracts all the cases with with noise = 10

```{r}
filter(df, noise == 10)
```

This extracts the cases with x\>2

```{r}
filter(df, x>2)
```

This extracts all the cases with x\>2 AND y\>10

```{r}
filter(df, (x>2)&(y>10)) # the & is an AND
```

```{r}
sigma2_vals
```

```{r}
length(sigma2_vals)
```

```{r}
1:length(sigma2_vals)
```

```{r}
correlations=c() # empty to start
for(j in 1:length(sigma2_vals)){
  sigma2 = sigma2_vals[j] # look at just the j-th noise case
  x_filtered = filter(df, noise == sigma2)$x # extract x and y values for this case
  y_filtered = filter(df, noise == sigma2)$y
  cor_est = cor(x_filtered, y_filtered) # compute the correlation
  correlations <- append(correlations, cor_est) # store in the array
}
correlations
```

Greater noise, less correlation. Graphically:

```{r}
cubic.plt=ggplot(df) + geom_point(aes(x,y, color=noise))
cubic.plt = cubic.plt + scale_color_discrete(name="Noise Intensity")
print(cubic.plt)
```

## Auto Data Set Problem

`Auto` dataframe

```{r}
Auto
```

```{r}
cor(Auto) # many of the features (columns) are not numerical values (real and integer values)
```

Filter the numerical features:

```{r}
select_if(Auto, is.numeric)
```

Get the pair correlations amongst all the numerical variables:

```{r}
cor(select_if(Auto, is.numeric))
```

**NOTE** The matrix is symmetric because

$$
 \mathrm{Cor}(X,Y) =  \mathrm{Cor}(Y,X) 
$$

and

$$
\mathrm{Cor}(X,X) = 1,
$$

always.

Looking ahead: we will build statistical models with the insight that more strongly correlated variables are more important to the model.

Graphically visualize pair correlations:

```{r}
pairs(select_if(Auto, is.numeric))
```

# More on ggplot

## Pair Correlations

A `ggplot`, `ggpairs`, provides better pair correlation figures, but it requires the `GGally` package to be installed

```{r}
library(GGally)
```

```{r}
auto.pairs.plt = ggpairs(select_if(Auto, is.numeric)) + 
  ggtitle("Pair Correlations for Auto")
print(auto.pairs.plt)
```

## Facets and Grids

This is a convenient way of visualizing a lot of features in a single figure

Layout subplots

```{r}
Auto.facet.gplt = ggplot(Auto) + geom_point(aes(horsepower, mpg))
Auto.facet.gplt = Auto.facet.gplt + facet_wrap(~cylinders, nrow=2) # filters the data by cylinder count and does the hp vs mpg for each case
Auto.facet.gplt = Auto.facet.gplt + ggtitle("Horsepower vs mpg, by Cylinders")
print(Auto.facet.gplt)
```

```{r}
Auto.facet.gplt = ggplot(Auto) + geom_point(aes(horsepower, mpg))
Auto.facet.gplt = Auto.facet.gplt + facet_wrap(~origin, nrow=2) # filters the data by origin count and does the hp vs mpg for each case
Auto.facet.gplt = Auto.facet.gplt + ggtitle("Horsepower vs mpg, by Origin")
print(Auto.facet.gplt)
```

We can use `facet_grid` to split along two different categorical variables

```{r}
Auto.grid.gplt = ggplot(Auto) + geom_point(aes(horsepower, mpg))
Auto.grid.gplt = Auto.grid.gplt + facet_grid(origin~cylinders) # filter data, simultaneously by origin and cylinders
Auto.grid.gplt = Auto.grid.gplt+ ggtitle("Horsepower vs mpg, by Cylinders and Origin")
print(Auto.grid.gplt)
```

It's really the cylinder count that's controlling hp vs. mpg, not origin.

## QQ Plots (revisited)

Is MPG normally distributed?

```{r}
auto.qq1.plt <- ggplot(Auto, aes(sample=mpg))+geom_qq()+geom_qq_line()
print(auto.qq1.plt)

```

This is not normally distributed.

What happens if we break out by origin?

```{r}
auto.qq2.plt <- ggplot(Auto, aes(sample=mpg, color=origin))+geom_qq()+geom_qq_line()
print(auto.qq2.plt)

```

Region 3 looks normal, region 2 is almost normal, region 1 is not.

What about cylinders?

```{r}
auto.qq2.plt <- ggplot(Auto, aes(sample=mpg, color=cylinders))+geom_qq()+geom_qq_line()
print(auto.qq2.plt)

```
